{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install pesq"
      ],
      "metadata": {
        "id": "MWb1KOvCdVC5",
        "outputId": "bbaea714-965c-44cb-8e44-123f9194c253",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pesq\n",
            "  Downloading pesq-0.0.4.tar.gz (38 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Building wheels for collected packages: pesq\n",
            "  Building wheel for pesq (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pesq: filename=pesq-0.0.4-cp311-cp311-linux_x86_64.whl size=274948 sha256=64a7d720d88a916a320fdd8eaac1d042b61d4caab777d23e2ae91e16c5754105\n",
            "  Stored in directory: /root/.cache/pip/wheels/ae/f1/23/2698d0bf31eec2b2aa50623b5d93b6206c49c7155d0e31345d\n",
            "Successfully built pesq\n",
            "Installing collected packages: pesq\n",
            "Successfully installed pesq-0.0.4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "TxcmY4ZKdFCi"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "import numpy as np\n",
        "import pickle\n",
        "from pesq import pesq\n",
        "import librosa\n",
        "import os"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Encoder: Generates the watermark perturbation\n",
        "class Encoder(nn.Module):\n",
        "    def __init__(self, input_size):\n",
        "        super(Encoder, self).__init__()\n",
        "        self.fc1 = nn.Linear(input_size, 512)\n",
        "        self.fc2 = nn.Linear(512, input_size)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = torch.relu(self.fc1(x))\n",
        "        perturbation = torch.tanh(self.fc2(x)) * 0.01  # Scaled perturbation\n",
        "        return perturbation"
      ],
      "metadata": {
        "id": "2sxe8e5SroRn"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Decoder: Detects the watermark\n",
        "class Decoder(nn.Module):\n",
        "    def __init__(self, input_size):\n",
        "        super(Decoder, self).__init__()\n",
        "        self.fc1 = nn.Linear(input_size, 512)\n",
        "        self.fc2 = nn.Linear(512, 1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = torch.relu(self.fc1(x))\n",
        "        return torch.sigmoid(self.fc2(x))"
      ],
      "metadata": {
        "id": "DYfkROXlrubp"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Audio Dataset\n",
        "class AudioDataset(Dataset):\n",
        "    def __init__(self, audio_paths, max_length=96000):\n",
        "        self.audio_paths = audio_paths\n",
        "        self.max_length = max_length\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.audio_paths)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        audio, sr = librosa.load(self.audio_paths[idx], sr=16000, mono=True)\n",
        "        audio = torch.from_numpy(audio).float()\n",
        "        original_length = len(audio)\n",
        "        if original_length < self.max_length:\n",
        "            audio = torch.nn.functional.pad(audio, (0, self.max_length - original_length))\n",
        "        else:\n",
        "            audio = audio[:self.max_length]\n",
        "        return audio, original_length"
      ],
      "metadata": {
        "id": "RMWc-Rjsry5D"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Training Loop\n",
        "def train(encoder, decoder, dataloader, device, num_epochs=10):\n",
        "    optimizer_enc = optim.Adam(encoder.parameters(), lr=0.001)\n",
        "    optimizer_dec = optim.Adam(decoder.parameters(), lr=0.001)\n",
        "    criterion = nn.BCELoss()\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        total_dec_loss = 0.0\n",
        "        total_enc_loss = 0.0\n",
        "        num_batches = 0\n",
        "\n",
        "        for audio, original_length in dataloader:\n",
        "            audio = audio.to(device)\n",
        "            batch_size = audio.size(0)\n",
        "            num_batches += 1\n",
        "\n",
        "            # Train Decoder\n",
        "            optimizer_dec.zero_grad()\n",
        "            pred_original = decoder(audio)  # Predict 0 for original audio\n",
        "            loss_original = criterion(pred_original, torch.zeros(batch_size, 1).to(device))\n",
        "            perturbation = encoder(audio)\n",
        "            watermarked = audio + perturbation\n",
        "            pred_watermarked = decoder(watermarked)  # Predict 1 for watermarked audio\n",
        "            loss_watermarked = criterion(pred_watermarked, torch.ones(batch_size, 1).to(device))\n",
        "            loss_dec = (loss_original + loss_watermarked) / 2\n",
        "            loss_dec.backward()\n",
        "            optimizer_dec.step()\n",
        "\n",
        "            # Train Encoder\n",
        "            optimizer_enc.zero_grad()\n",
        "            pred_watermarked = decoder(watermarked)\n",
        "            loss_detection = criterion(pred_watermarked, torch.ones(batch_size, 1).to(device))  # Ensure watermark is detectable\n",
        "            loss_perceptual = torch.mean(perturbation ** 2)  # Minimize distortion (MSE proxy for PESQ)\n",
        "            loss_enc = loss_detection + 0.1 * loss_perceptual  # Balance detection and quality\n",
        "            loss_enc.backward()\n",
        "            optimizer_enc.step()\n",
        "\n",
        "            total_dec_loss += loss_dec.item()\n",
        "            total_enc_loss += loss_enc.item()\n",
        "\n",
        "        avg_dec_loss = total_dec_loss / num_batches\n",
        "        avg_enc_loss = total_enc_loss / num_batches\n",
        "        print(f\"Epoch {epoch+1}/{num_epochs}: Decoder Loss: {avg_dec_loss:.4f}, Encoder Loss: {avg_enc_loss:.4f}\")"
      ],
      "metadata": {
        "id": "-ATiW0XIrzzd"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lNB7NE2e5odD",
        "outputId": "b5f70bea-e83d-4ee1-89ec-ec10f189a2e5"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pwd"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wunsvtid5Dim",
        "outputId": "b49f636e-8ba7-4ca6-8479-4b9b65a5ce1e"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ls"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Mpfb9Ymt5jAm",
        "outputId": "a555bcd1-a6e9-47b2-bd6e-f37c38e226b4"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "drive  sample_data\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "path_lst = []\n",
        "audio_dir = f\"drive/MyDrive/Semester-2/Speech and Audio/Project/Speaker-Recognition-Audio-Dataset/\"\n",
        "for folder in os.listdir(audio_dir):\n",
        "    folder_path = os.path.join(audio_dir, folder)\n",
        "    if os.path.isdir(folder_path):\n",
        "        for filename in os.listdir(folder_path):\n",
        "            if filename.endswith('.wav'):  # Ensure only audio files are included\n",
        "                audio_path = os.path.join(folder_path, filename)\n",
        "                path_lst.append(audio_path)"
      ],
      "metadata": {
        "id": "EYaqZa2ygO_R"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create Dataset and DataLoader\n",
        "dataset = AudioDataset(path_lst, max_length=96000)  # 6 seconds at 16kHz\n",
        "dataloader = DataLoader(dataset, batch_size=4, shuffle=True)  # Batch size increased for efficiency"
      ],
      "metadata": {
        "id": "frrf64N_60Va"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Set Device and Initialize Models\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "encoder = Encoder(96000).to(device)  # Input size fixed to 6 seconds at 16kHz\n",
        "decoder = Decoder(96000).to(device)\n",
        "\n",
        "# Train the Models\n",
        "train(encoder, decoder, dataloader, device, num_epochs=10)"
      ],
      "metadata": {
        "id": "R4LdLkFJ60RA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Save Models (Optional)\n",
        "torch.save(encoder.state_dict(), \"drive/MyDrive/encoder.pth\")\n",
        "torch.save(decoder.state_dict(), \"drive/MyDrive/decoder.pth\")"
      ],
      "metadata": {
        "id": "9ycig62p60M1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "8auNtWYA60HW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "87lQ4P_56z8d"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}